{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pip._vendor.requests as requests\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from  sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "scope1 = \"user-library-read\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_csv(\"total.csv\")\n",
    "df_total\n",
    "df_total.loc[df_total[\"tag\"] == \"calm\", \"tag\"] = 0\n",
    "df_total.loc[df_total[\"tag\"] == \"happy\", \"tag\"] = 1\n",
    "df_total.loc[df_total[\"tag\"] == \"energ\", \"tag\"] = 2\n",
    "df_total.loc[df_total[\"tag\"] == \"sad\", \"tag\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calm = pd.read_csv(\"soft_mix.csv\")\n",
    "df_calm = df_calm.drop(columns=['Spotify ID', 'Artist IDs', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', \n",
    "                                'Duration (ms)', 'Genres', 'Popularity', 'Added By', 'Added At', 'Mode', 'Time Signature'])\n",
    "df_calm[\"tag\"]=0\n",
    "\n",
    "\n",
    "df_energ = pd.read_csv(\"hype_workout_mix.csv\")\n",
    "df_energ = df_energ.drop(columns=['Spotify ID', 'Artist IDs', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', \n",
    "                                'Duration (ms)', 'Genres', 'Popularity', 'Added By', 'Added At', 'Mode', 'Time Signature'])\n",
    "df_energ[\"tag\"]=2\n",
    "\n",
    "df_happy = pd.read_csv(\"feel_good_happy_mix.csv\")\n",
    "df_happy = df_happy.drop(columns=['Spotify ID', 'Artist IDs', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', \n",
    "                                'Duration (ms)', 'Genres', 'Popularity', 'Added By', 'Added At', 'Mode', 'Time Signature'])\n",
    "df_happy[\"tag\"]=1\n",
    "\n",
    "df_sad = pd.read_csv(\"lonely_sad_mix.csv\")\n",
    "df_sad = df_sad.drop(columns=['Spotify ID', 'Artist IDs', 'Track Name', 'Album Name', 'Artist Name(s)', 'Release Date', \n",
    "                                'Duration (ms)', 'Genres', 'Popularity', 'Added By', 'Added At', 'Mode', 'Time Signature'])\n",
    "df_sad[\"tag\"]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = df_calm[[\"Tempo\"]].min()\n",
    "max_value = df_calm[[\"Tempo\"]].max()\n",
    "df_calm[\"Tempo\"] = (df_calm[[\"Tempo\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_calm[[\"Loudness\"]].min()\n",
    "max_value = df_calm[[\"Loudness\"]].max()\n",
    "df_calm[\"Loudness\"] = (df_calm[[\"Loudness\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_calm[[\"Key\"]].min()\n",
    "max_value = df_calm[[\"Key\"]].max()\n",
    "df_calm[\"Key\"] = (df_calm[[\"Key\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "\n",
    "\n",
    "min_value = df_energ[[\"Tempo\"]].min()\n",
    "max_value = df_energ[[\"Tempo\"]].max()\n",
    "df_energ[\"Tempo\"] = (df_energ[[\"Tempo\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_energ[[\"Loudness\"]].min()\n",
    "max_value = df_energ[[\"Loudness\"]].max()\n",
    "df_energ[\"Loudness\"] = (df_energ[[\"Loudness\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_energ[[\"Key\"]].min()\n",
    "max_value = df_energ[[\"Key\"]].max()\n",
    "df_energ[\"Key\"] = (df_energ[[\"Key\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "\n",
    "\n",
    "min_value = df_happy[[\"Tempo\"]].min()\n",
    "max_value = df_happy[[\"Tempo\"]].max()\n",
    "df_happy[\"Tempo\"] = (df_happy[[\"Tempo\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_happy[[\"Loudness\"]].min()\n",
    "max_value = df_happy[[\"Loudness\"]].max()\n",
    "df_happy[\"Loudness\"] = (df_happy[[\"Loudness\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_happy[[\"Key\"]].min()\n",
    "max_value = df_happy[[\"Key\"]].max()\n",
    "df_happy[\"Key\"] = (df_happy[[\"Key\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "\n",
    "\n",
    "min_value = df_sad[[\"Tempo\"]].min()\n",
    "max_value = df_sad[[\"Tempo\"]].max()\n",
    "df_sad[\"Tempo\"] = (df_sad[[\"Tempo\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_sad[[\"Loudness\"]].min()\n",
    "max_value = df_sad[[\"Loudness\"]].max()\n",
    "df_sad[\"Loudness\"] = (df_sad[[\"Loudness\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_sad[[\"Key\"]].min()\n",
    "max_value = df_sad[[\"Key\"]].max()\n",
    "df_sad[\"Key\"] = (df_sad[[\"Key\"]] - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m data_calm \u001b[39m=\u001b[39m df_calm[[\u001b[39m\"\u001b[39m\u001b[39mDanceability\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEnergy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mKey\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoudness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSpeechiness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAcousticness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mInstrumentalness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLiveness\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mValence\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTempo\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m     19\u001b[0m data_calm_target \u001b[39m=\u001b[39m df_calm[[\u001b[39m\"\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m data_calm \u001b[39m=\u001b[39m df_calm\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m data_calm\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'array'"
     ]
    }
   ],
   "source": [
    "# Normalize the DataFrame to be between 0 and 1\n",
    "min_value = df_total[[\"Tempo\"]].min()\n",
    "max_value = df_total[[\"Tempo\"]].max()\n",
    "df_total[\"Tempo\"] = (df_total[[\"Tempo\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_total[[\"Loudness\"]].min()\n",
    "max_value = df_total[[\"Loudness\"]].max()\n",
    "df_total[\"Loudness\"] = (df_total[[\"Loudness\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "min_value = df_total[[\"Key\"]].min()\n",
    "max_value = df_total[[\"Key\"]].max()\n",
    "df_total[\"Key\"] = (df_total[[\"Key\"]] - min_value) / (max_value - min_value)\n",
    "\n",
    "\n",
    "data = df_total[[\"Danceability\", \"Energy\", \"Key\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\", \"Liveness\", \"Valence\", \"Tempo\"]]\n",
    "data_target = df_total[[\"tag\"]].astype(int)\n",
    "\n",
    "data_calm = df_calm[[\"Danceability\", \"Energy\", \"Key\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\", \"Liveness\", \"Valence\", \"Tempo\"]]\n",
    "data_calm_target = df_calm[[\"tag\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.502      0.168      0.         0.61230469 0.0355     0.969\n 0.971      0.111      0.158      0.93137047 0.27       0.188\n 0.8        0.4499783  0.0404     0.978      0.97       0.109\n 0.085      0.29919486 0.547      0.193      0.5        0.65798611\n 0.0386     0.953      0.735      0.191      0.221      1.\n 0.531      0.211      0.5        0.60177951 0.0361     0.928\n 0.797      0.0939     0.206      0.17820033 0.515      0.132\n 0.5        0.35145399 0.0372     0.962      0.939      0.109\n 0.143      0.         0.542      0.0817     0.         0.23860677\n 0.0384     0.93       0.235      0.108      0.288      0.36761284\n 0.483      0.167      0.5        0.72070312 0.0341     0.936\n 0.9        0.0863     0.169      0.59541557 0.255      0.0745\n 0.         0.17469618 0.0395     0.863      0.128      0.133\n 0.179      0.33854329 0.418      0.153      0.8        0.25119358\n 0.0352     0.956      0.903      0.096      0.0627     0.98407148\n 0.513      0.259      0.2        0.96169705 0.0315     0.918\n 0.807      0.107      0.107      0.36273473 0.563      0.148\n 0.8        0.359375   0.0398     0.873      0.772      0.101\n 0.1        0.92244801 0.374      0.0765     0.5        0.19965278\n 0.0341     0.989      0.954      0.165      0.11       0.70532237\n 0.392      0.175      0.2        0.28559028 0.0349     0.986\n 0.866      0.125      0.259      0.73082044 0.392      0.162\n 0.         0.35872396 0.0421     0.979      0.745      0.124\n 0.189      0.58392962 0.544      0.203      1.         0.63161892\n 0.0419     0.946      0.314      0.103      0.251      0.79927575\n 0.557      0.16       1.         0.54253472 0.0401     0.96\n 0.886      0.0926     0.0577     0.92916786 0.406      0.0835\n 0.4        0.         0.0322     0.965      0.156      0.209\n 0.109      0.52001643 0.386      0.164      0.9        0.57845052\n 0.0334     0.911      0.319      0.0847     0.0672     0.40360134\n 0.59       0.135      0.5        0.57519531 0.0455     0.973\n 0.839      0.112      0.359      0.8974477  0.342      0.202\n 1.         0.55718316 0.0415     0.947      0.67       0.119\n 0.292      0.09516047 0.455      0.26       0.         0.74012587\n 0.0385     0.973      0.946      0.26       0.204      0.96348884\n 0.41       0.138      0.6        0.30707465 0.0317     0.961\n 0.893      0.234      0.0812     0.46934382 0.557      0.229\n 0.7        0.5921224  0.0359     0.853      0.423      0.0984\n 0.0816     0.16335445 0.516      0.159      0.5        0.67415365\n 0.0377     0.972      0.895      0.0856     0.196      0.83404472\n 0.442      0.174      0.         0.33626302 0.032      0.941\n 0.85       0.11       0.129      0.67385109 0.615      0.186\n 0.8        0.5766059  0.0494     0.96       0.888      0.351\n 0.195      0.87952812 0.526      0.152      0.7        0.53786892\n 0.0373     0.951      0.888      0.123      0.144      0.81550293\n 0.345      0.133      0.2        0.33485243 0.0331     0.949\n 0.559      0.0804     0.0744     0.37764283 0.552      0.113\n 0.5        0.22276476 0.0371     0.964      0.672      0.123\n 0.207      0.19007205 0.364      0.187      0.2        0.26356337\n 0.0329     0.979      0.915      0.0832     0.0902     0.41360644\n 0.54       0.176      0.2        0.72938368 0.0383     0.961\n 0.0187     0.139      0.279      0.75904379 0.511      0.274\n 0.5        1.         0.0357     0.952      0.679      0.112\n 0.118      0.25911223 0.561      0.133      0.2        0.50889757\n 0.0436     0.959      0.938      0.135      0.181      0.76857602\n 0.458      0.0922     0.5        0.07486979 0.0373     0.952\n 0.756      0.106      0.112      0.79887754 0.51       0.134\n 0.7        0.21885851 0.0334     0.932      0.956      0.375\n 0.182      0.62245673 0.609      0.147      0.4        0.64105903\n 0.0459     0.967      0.924      0.0971     0.109      0.91067584\n 0.453      0.203      0.7        0.78266059 0.0362     0.976\n 0.904      0.116      0.197      0.78312323 0.445      0.21\n 0.6        0.47667101 0.034      0.969      0.973      0.101\n 0.182      0.05374631 0.474      0.172      0.5        0.51898872\n 0.037      0.953      0.949      0.106      0.116      0.8041663\n 0.437      0.0956     0.7        0.51258681 0.0315     0.982\n 0.296      0.135      0.16       0.66797745 0.467      0.0856\n 1.         0.12261285 0.0346     0.903      0.647      0.143\n 0.115      0.39699349 0.518      0.147      1.         0.52734375\n 0.038      0.954      0.976      0.123      0.161      0.77110218\n 0.552      0.0863     0.7        0.28374566 0.0316     0.934\n 0.982      0.126      0.188      0.1239438  0.615      0.195\n 0.1        0.44802517 0.0339     0.979      0.907      0.264\n 0.172      0.03313879 0.352      0.233      0.         0.60026042\n 0.0405     0.933      0.924      0.0966     0.159      0.81091104\n 0.414      0.154      0.         0.38953993 0.0442     0.973\n 0.892      0.107      0.119      0.85015991 0.526      0.131\n 0.         0.42740885 0.0368     0.947      0.853      0.349\n 0.176      0.79913886 0.538      0.161      0.         0.68945312\n 0.0518     0.982      0.296      0.291      0.21       0.90646972\n 0.55       0.151      0.3        0.42133247 0.0347     0.97\n 0.865      0.111      0.106      0.82374096 0.632      0.481\n 0.6        0.62044271 0.0611     0.199      0.763      0.112\n 0.229      0.76500454].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/multiclass.py:98\u001b[0m, in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(estimator\u001b[39m.\u001b[39;49mdecision_function(X))\n\u001b[1;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m     \u001b[39m# probabilities of the positive class\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m data_calm_target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(data_calm_target)\n\u001b[1;32m      8\u001b[0m model\u001b[39m.\u001b[39mfit(song_x_train,song_y_train)\n\u001b[0;32m----> 9\u001b[0m data_predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(data_calm)\n\u001b[1;32m     10\u001b[0m output \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mRMSE\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39msqrt(mean_squared_error(data_calm_target,data_predict)), \u001b[39m\"\u001b[39m\u001b[39maccuracy_score\u001b[39m\u001b[39m\"\u001b[39m:metrics\u001b[39m.\u001b[39maccuracy_score(data_calm_target, data_predict)}\n\u001b[1;32m     11\u001b[0m df_result\u001b[39m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/multiclass.py:438\u001b[0m, in \u001b[0;36mOneVsRestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    436\u001b[0m argmaxima \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(n_samples, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m    437\u001b[0m \u001b[39mfor\u001b[39;00m i, e \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_):\n\u001b[0;32m--> 438\u001b[0m     pred \u001b[39m=\u001b[39m _predict_binary(e, X)\n\u001b[1;32m    439\u001b[0m     np\u001b[39m.\u001b[39mmaximum(maxima, pred, out\u001b[39m=\u001b[39mmaxima)\n\u001b[1;32m    440\u001b[0m     argmaxima[maxima \u001b[39m==\u001b[39m pred] \u001b[39m=\u001b[39m i\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/multiclass.py:101\u001b[0m, in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m     98\u001b[0m     score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mravel(estimator\u001b[39m.\u001b[39mdecision_function(X))\n\u001b[1;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m     \u001b[39m# probabilities of the positive class\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     score \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mpredict_proba(X)[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1242\u001b[0m, in \u001b[0;36mMLPClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Probability estimates.\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \n\u001b[1;32m   1230\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39m    model, where classes are ordered as they are in `self.classes_`.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1242\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass_fast(X)\n\u001b[1;32m   1244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1245\u001b[0m     y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:202\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[39mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 202\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    204\u001b[0m \u001b[39m# Initialize first layer\u001b[39;00m\n\u001b[1;32m    205\u001b[0m activation \u001b[39m=\u001b[39m X\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    907\u001b[0m         )\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.502      0.168      0.         0.61230469 0.0355     0.969\n 0.971      0.111      0.158      0.93137047 0.27       0.188\n 0.8        0.4499783  0.0404     0.978      0.97       0.109\n 0.085      0.29919486 0.547      0.193      0.5        0.65798611\n 0.0386     0.953      0.735      0.191      0.221      1.\n 0.531      0.211      0.5        0.60177951 0.0361     0.928\n 0.797      0.0939     0.206      0.17820033 0.515      0.132\n 0.5        0.35145399 0.0372     0.962      0.939      0.109\n 0.143      0.         0.542      0.0817     0.         0.23860677\n 0.0384     0.93       0.235      0.108      0.288      0.36761284\n 0.483      0.167      0.5        0.72070312 0.0341     0.936\n 0.9        0.0863     0.169      0.59541557 0.255      0.0745\n 0.         0.17469618 0.0395     0.863      0.128      0.133\n 0.179      0.33854329 0.418      0.153      0.8        0.25119358\n 0.0352     0.956      0.903      0.096      0.0627     0.98407148\n 0.513      0.259      0.2        0.96169705 0.0315     0.918\n 0.807      0.107      0.107      0.36273473 0.563      0.148\n 0.8        0.359375   0.0398     0.873      0.772      0.101\n 0.1        0.92244801 0.374      0.0765     0.5        0.19965278\n 0.0341     0.989      0.954      0.165      0.11       0.70532237\n 0.392      0.175      0.2        0.28559028 0.0349     0.986\n 0.866      0.125      0.259      0.73082044 0.392      0.162\n 0.         0.35872396 0.0421     0.979      0.745      0.124\n 0.189      0.58392962 0.544      0.203      1.         0.63161892\n 0.0419     0.946      0.314      0.103      0.251      0.79927575\n 0.557      0.16       1.         0.54253472 0.0401     0.96\n 0.886      0.0926     0.0577     0.92916786 0.406      0.0835\n 0.4        0.         0.0322     0.965      0.156      0.209\n 0.109      0.52001643 0.386      0.164      0.9        0.57845052\n 0.0334     0.911      0.319      0.0847     0.0672     0.40360134\n 0.59       0.135      0.5        0.57519531 0.0455     0.973\n 0.839      0.112      0.359      0.8974477  0.342      0.202\n 1.         0.55718316 0.0415     0.947      0.67       0.119\n 0.292      0.09516047 0.455      0.26       0.         0.74012587\n 0.0385     0.973      0.946      0.26       0.204      0.96348884\n 0.41       0.138      0.6        0.30707465 0.0317     0.961\n 0.893      0.234      0.0812     0.46934382 0.557      0.229\n 0.7        0.5921224  0.0359     0.853      0.423      0.0984\n 0.0816     0.16335445 0.516      0.159      0.5        0.67415365\n 0.0377     0.972      0.895      0.0856     0.196      0.83404472\n 0.442      0.174      0.         0.33626302 0.032      0.941\n 0.85       0.11       0.129      0.67385109 0.615      0.186\n 0.8        0.5766059  0.0494     0.96       0.888      0.351\n 0.195      0.87952812 0.526      0.152      0.7        0.53786892\n 0.0373     0.951      0.888      0.123      0.144      0.81550293\n 0.345      0.133      0.2        0.33485243 0.0331     0.949\n 0.559      0.0804     0.0744     0.37764283 0.552      0.113\n 0.5        0.22276476 0.0371     0.964      0.672      0.123\n 0.207      0.19007205 0.364      0.187      0.2        0.26356337\n 0.0329     0.979      0.915      0.0832     0.0902     0.41360644\n 0.54       0.176      0.2        0.72938368 0.0383     0.961\n 0.0187     0.139      0.279      0.75904379 0.511      0.274\n 0.5        1.         0.0357     0.952      0.679      0.112\n 0.118      0.25911223 0.561      0.133      0.2        0.50889757\n 0.0436     0.959      0.938      0.135      0.181      0.76857602\n 0.458      0.0922     0.5        0.07486979 0.0373     0.952\n 0.756      0.106      0.112      0.79887754 0.51       0.134\n 0.7        0.21885851 0.0334     0.932      0.956      0.375\n 0.182      0.62245673 0.609      0.147      0.4        0.64105903\n 0.0459     0.967      0.924      0.0971     0.109      0.91067584\n 0.453      0.203      0.7        0.78266059 0.0362     0.976\n 0.904      0.116      0.197      0.78312323 0.445      0.21\n 0.6        0.47667101 0.034      0.969      0.973      0.101\n 0.182      0.05374631 0.474      0.172      0.5        0.51898872\n 0.037      0.953      0.949      0.106      0.116      0.8041663\n 0.437      0.0956     0.7        0.51258681 0.0315     0.982\n 0.296      0.135      0.16       0.66797745 0.467      0.0856\n 1.         0.12261285 0.0346     0.903      0.647      0.143\n 0.115      0.39699349 0.518      0.147      1.         0.52734375\n 0.038      0.954      0.976      0.123      0.161      0.77110218\n 0.552      0.0863     0.7        0.28374566 0.0316     0.934\n 0.982      0.126      0.188      0.1239438  0.615      0.195\n 0.1        0.44802517 0.0339     0.979      0.907      0.264\n 0.172      0.03313879 0.352      0.233      0.         0.60026042\n 0.0405     0.933      0.924      0.0966     0.159      0.81091104\n 0.414      0.154      0.         0.38953993 0.0442     0.973\n 0.892      0.107      0.119      0.85015991 0.526      0.131\n 0.         0.42740885 0.0368     0.947      0.853      0.349\n 0.176      0.79913886 0.538      0.161      0.         0.68945312\n 0.0518     0.982      0.296      0.291      0.21       0.90646972\n 0.55       0.151      0.3        0.42133247 0.0347     0.97\n 0.865      0.111      0.106      0.82374096 0.632      0.481\n 0.6        0.62044271 0.0611     0.199      0.763      0.112\n 0.229      0.76500454].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "song_x_train, song_x_test, song_y_train, song_y_test = train_test_split(data, data_target, test_size= 0.2, random_state= 42, shuffle=True)\n",
    "df_result = []\n",
    "\n",
    "for i in range(1):\n",
    "    model = OneVsRestClassifier(MLPClassifier(hidden_layer_sizes= (16, 10,), activation= \"logistic\",max_iter= 1000, learning_rate_init= 0.01, alpha = 0.01), n_jobs = -1)\n",
    "    data_calm = np.ravel(data_calm)\n",
    "    data_calm_target = np.ravel(data_calm_target)\n",
    "    model.fit(song_x_train,song_y_train)\n",
    "    data_predict = model.predict(data_calm)\n",
    "    output = {\"RMSE\": np.sqrt(mean_squared_error(data_calm_target,data_predict)), \"accuracy_score\":metrics.accuracy_score(data_calm_target, data_predict)}\n",
    "    df_result.append(output)\n",
    "        # print(\"RMSE\", np.sqrt(mean_squared_error(song_y_test,song_y_predict)))\n",
    "        # print(metrics.accuracy_score(song_y_test, song_y_predict))\n",
    "        # print(\"------\")\n",
    "df_output = pd.DataFrame(df_result)\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.69687476,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.39374951,  1.39374951,  2.78749902,  3.48437378,\n",
       "         6.2718728 ,  3.48437378,  8.36249707,  9.75624658, 11.14999609,\n",
       "        12.5437456 , 11.84687085, 20.20936791, 20.20936791, 27.17811547,\n",
       "        37.6312368 , 34.14686302, 27.87499022, 36.23748729, 26.48124071,\n",
       "        50.87185716, 28.57186498, 37.6312368 , 36.93436205, 30.66248925,\n",
       "        32.75311351, 31.359364  , 23.69374169, 22.29999218, 20.90624267,\n",
       "        12.5437456 , 13.24062036, 16.02811938,  8.36249707,  6.96874756,\n",
       "         5.57499804,  5.57499804,  4.18124853,  0.69687476,  1.39374951,\n",
       "         0.        ,  0.69687476,  0.69687476,  1.39374951,  0.69687476]),\n",
       " array([0.66261867, 0.66405364, 0.66548862, 0.6669236 , 0.66835858,\n",
       "        0.66979356, 0.67122853, 0.67266351, 0.67409849, 0.67553347,\n",
       "        0.67696845, 0.67840343, 0.6798384 , 0.68127338, 0.68270836,\n",
       "        0.68414334, 0.68557832, 0.68701329, 0.68844827, 0.68988325,\n",
       "        0.69131823, 0.69275321, 0.69418818, 0.69562316, 0.69705814,\n",
       "        0.69849312, 0.6999281 , 0.70136307, 0.70279805, 0.70423303,\n",
       "        0.70566801, 0.70710299, 0.70853797, 0.70997294, 0.71140792,\n",
       "        0.7128429 , 0.71427788, 0.71571286, 0.71714783, 0.71858281,\n",
       "        0.72001779, 0.72145277, 0.72288775, 0.72432272, 0.7257577 ,\n",
       "        0.72719268, 0.72862766, 0.73006264, 0.73149761, 0.73293259,\n",
       "        0.73436757]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = df_output[\"accuracy_score\"].mean()\n",
    "std = df_output[\"accuracy_score\"].std()\n",
    "normal = np.random.normal(mean, std, size = len(df_output))\n",
    "plt.hist(normal, bins = 50, density= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mood</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>energ</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>happy</td>\n",
       "      <td>energ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>calm</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>energ</td>\n",
       "      <td>energ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mood predicted\n",
       "0      sad       sad\n",
       "1     calm      calm\n",
       "2     calm      calm\n",
       "3    energ       sad\n",
       "4     calm      calm\n",
       "..     ...       ...\n",
       "296   calm      calm\n",
       "297  happy     energ\n",
       "298   calm      calm\n",
       "299   calm      calm\n",
       "300  energ     energ\n",
       "\n",
       "[301 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_y_test_copy = [0] * song_y_test.size\n",
    "song_y_predict_copy = [0] * song_y_predict.size\n",
    "\n",
    "for i in range(song_y_test.size):\n",
    "    song_y_test_copy[i] = song_y_test[i]\n",
    "for i in range(song_y_predict.size):\n",
    "    song_y_predict_copy[i] = song_y_predict[i]\n",
    "\n",
    "for i in range(data_predict.size):\n",
    "    if song_y_test_copy[i] == 0:\n",
    "        song_y_test_copy[i] = 'calm'\n",
    "    if song_y_test_copy[i] == 1:\n",
    "        song_y_test_copy[i] = 'happy'\n",
    "    if song_y_test_copy[i] == 2:\n",
    "        song_y_test_copy[i] = 'energ'\n",
    "    if song_y_test_copy[i] == 3:\n",
    "        song_y_test_copy[i] = 'sad'\n",
    "\n",
    "for i in range(data_predict.size):\n",
    "    if song_y_predict_copy[i] == 0:\n",
    "        song_y_predict_copy[i] = 'calm'\n",
    "    if song_y_predict_copy[i] == 1:\n",
    "        song_y_predict_copy[i] = 'happy'\n",
    "    if song_y_predict_copy[i] == 2:\n",
    "        song_y_predict_copy[i] = 'energ'\n",
    "    if song_y_predict_copy[i] == 3:\n",
    "        song_y_predict_copy[i] = 'sad'\n",
    "\n",
    "compare = pd.DataFrame({'mood': song_y_test_copy, 'predicted': song_y_predict_copy})\n",
    "compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
